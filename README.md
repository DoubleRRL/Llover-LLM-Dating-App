# Llover Dating App
# AI Security Analysis Platform

A security research platform simulating LLM-only chat with multiple AI personalities. Features real-time message security detection, personality-specific suggestions, and a security dashboard. No dialog tree or hybrid logicâ€”everything is powered by LLM responses.

## ðŸš© Project Overview

This platform lets you test and analyze AI personalities for social engineering and security vulnerabilities. It demonstrates:
- Real-time detection of risky messages (PII requests, phishing, data leaks, emotional manipulation)
- Personality-specific, realistic message suggestions (slang, lowercase, bad grammar)
- Security dashboard with live event log and metrics
- Read receipts, typing indicator, and persistent chat per personality

## Key Features
- **LLM-Only Chat**: All responses are generated by the LLM (no dialog tree)
- **Real-Time Security Detection**: Every message is analyzed for risky content and flagged in the UI
- **Personality-Specific Tips**: Each persona has unique, in-character suggestions for social engineering
- **Security Dashboard**: Visualizes metrics and logs detected security events
- **Modern UX**: Typing indicator, read receipts, auto-growing input, and more

## Tech Stack
- Next.js 14, React 18, TypeScript
- Tailwind CSS
- Ollama (Llama 3 model)

## Getting Started

1. Clone the repository:
   ```bash
   git clone <repository-url>
   cd simple-chat
   ```
2. Install dependencies:
   ```bash
   npm install
   ```
3. Start Ollama with Llama 3:
   ```bash
   ollama run llama3
   ```
4. Run the development server:
   ```bash
   npm run dev
   ```
5. Open [http://localhost:3000](http://localhost:3000) in your browser.

## Usage
- Select a personality from the sidebar
- Review their security profile and interests
- Use the rotating tips to test for vulnerabilities
- Watch the dashboard for real-time detection and event logs
- All chat is LLM-driven; no scripted dialog trees

## Security Metrics
- **Vulnerability Score**: How easily the AI can be manipulated
- **Trust Level**: How much the AI trusts and shares info
- **Manipulation Attempts**: Number of detected social engineering vectors
- **Event Log**: List of flagged risky messages

## Development
- `npm run dev` - Start dev server
- `npm run build` - Build for production
- `npm run start` - Start production server
- `npm run lint` - Run ESLint

## License
MIT License - for security research and educational use. 